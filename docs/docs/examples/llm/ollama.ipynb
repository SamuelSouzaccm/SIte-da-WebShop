{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "4d1b897a",
      "metadata": {
        "id": "4d1b897a"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/docs/examples/llm/ollama.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e33dced-e587-4397-81b3-d6606aa1738a",
      "metadata": {
        "id": "2e33dced-e587-4397-81b3-d6606aa1738a"
      },
      "source": [
        "# Ollama LLM"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5863dde9-84a0-4c33-ad52-cc767442f63f",
      "metadata": {
        "id": "5863dde9-84a0-4c33-ad52-cc767442f63f"
      },
      "source": [
        "## Setup\n",
        "First, follow the [readme](https://github.com/jmorganca/ollama) to set up and run a local Ollama instance.\n",
        "\n",
        "When the Ollama app is running on your local machine:\n",
        "- All of your local models are automatically served on localhost:11434\n",
        "- Select your model when setting llm = Ollama(..., model=\"<model family>:<version>\")\n",
        "- Increase defaullt timeout (30 seconds) if needed setting Ollama(..., request_timeout=300.0)\n",
        "- If you set llm = Ollama(..., model=\"<model family\") without a version it will simply look for latest\n",
        "- By default, the maximum context window for your model is used. You can manually set the `context_window` to limit memory usage."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "833bdb2b",
      "metadata": {
        "id": "833bdb2b"
      },
      "source": [
        "If you're opening this Notebook on colab, you will probably need to install LlamaIndex 🦙."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "4816bcb9",
      "metadata": {
        "id": "4816bcb9",
        "outputId": "b4f8e94b-348b-4d01-9997-4a334f93d80c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting llama-index-llms-ollama\n",
            "  Downloading llama_index_llms_ollama-0.6.2-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting llama-index-core<0.13,>=0.12.4 (from llama-index-llms-ollama)\n",
            "  Downloading llama_index_core-0.12.52.post1-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting ollama>=0.5.1 (from llama-index-llms-ollama)\n",
            "  Downloading ollama-0.5.1-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: aiohttp<4,>=3.8.6 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.4->llama-index-llms-ollama) (3.12.14)\n",
            "Collecting aiosqlite (from llama-index-core<0.13,>=0.12.4->llama-index-llms-ollama)\n",
            "  Downloading aiosqlite-0.21.0-py3-none-any.whl.metadata (4.3 kB)\n",
            "Collecting banks<3,>=2.2.0 (from llama-index-core<0.13,>=0.12.4->llama-index-llms-ollama)\n",
            "  Downloading banks-2.2.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting dataclasses-json (from llama-index-core<0.13,>=0.12.4->llama-index-llms-ollama)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting deprecated>=1.2.9.3 (from llama-index-core<0.13,>=0.12.4->llama-index-llms-ollama)\n",
            "  Downloading Deprecated-1.2.18-py2.py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting dirtyjson<2,>=1.0.8 (from llama-index-core<0.13,>=0.12.4->llama-index-llms-ollama)\n",
            "  Downloading dirtyjson-1.0.8-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting filetype<2,>=1.2.0 (from llama-index-core<0.13,>=0.12.4->llama-index-llms-ollama)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.4->llama-index-llms-ollama) (2025.3.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.4->llama-index-llms-ollama) (0.28.1)\n",
            "Collecting llama-index-workflows<2,>=1.0.1 (from llama-index-core<0.13,>=0.12.4->llama-index-llms-ollama)\n",
            "  Downloading llama_index_workflows-1.2.0-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.4->llama-index-llms-ollama) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.4->llama-index-llms-ollama) (3.5)\n",
            "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.4->llama-index-llms-ollama) (3.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.4->llama-index-llms-ollama) (2.0.2)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.4->llama-index-llms-ollama) (11.3.0)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.4->llama-index-llms-ollama) (4.3.8)\n",
            "Requirement already satisfied: pydantic>=2.8.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.4->llama-index-llms-ollama) (2.11.7)\n",
            "Requirement already satisfied: pyyaml>=6.0.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.4->llama-index-llms-ollama) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.4->llama-index-llms-ollama) (2.32.3)\n",
            "Collecting setuptools>=80.9.0 (from llama-index-core<0.13,>=0.12.4->llama-index-llms-ollama)\n",
            "  Downloading setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.49 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.13,>=0.12.4->llama-index-llms-ollama) (2.0.41)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.4->llama-index-llms-ollama) (8.5.0)\n",
            "Requirement already satisfied: tiktoken>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.4->llama-index-llms-ollama) (0.9.0)\n",
            "Requirement already satisfied: tqdm<5,>=4.66.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.4->llama-index-llms-ollama) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.4->llama-index-llms-ollama) (4.14.1)\n",
            "Collecting typing-inspect>=0.8.0 (from llama-index-core<0.13,>=0.12.4->llama-index-llms-ollama)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.4->llama-index-llms-ollama) (1.17.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.4->llama-index-llms-ollama) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.4->llama-index-llms-ollama) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.4->llama-index-llms-ollama) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.4->llama-index-llms-ollama) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.4->llama-index-llms-ollama) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.4->llama-index-llms-ollama) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.4->llama-index-llms-ollama) (1.20.1)\n",
            "Collecting griffe (from banks<3,>=2.2.0->llama-index-core<0.13,>=0.12.4->llama-index-llms-ollama)\n",
            "  Downloading griffe-1.8.0-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from banks<3,>=2.2.0->llama-index-core<0.13,>=0.12.4->llama-index-llms-ollama) (3.1.6)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.13,>=0.12.4->llama-index-llms-ollama) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.13,>=0.12.4->llama-index-llms-ollama) (2025.7.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.13,>=0.12.4->llama-index-llms-ollama) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.13,>=0.12.4->llama-index-llms-ollama) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.13,>=0.12.4->llama-index-llms-ollama) (0.16.0)\n",
            "Collecting llama-index-instrumentation>=0.1.0 (from llama-index-workflows<2,>=1.0.1->llama-index-core<0.13,>=0.12.4->llama-index-llms-ollama)\n",
            "  Downloading llama_index_instrumentation-0.3.0-py3-none-any.whl.metadata (252 bytes)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index-core<0.13,>=0.12.4->llama-index-llms-ollama) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index-core<0.13,>=0.12.4->llama-index-llms-ollama) (1.5.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index-core<0.13,>=0.12.4->llama-index-llms-ollama) (2024.11.6)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core<0.13,>=0.12.4->llama-index-llms-ollama) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core<0.13,>=0.12.4->llama-index-llms-ollama) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core<0.13,>=0.12.4->llama-index-llms-ollama) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->llama-index-core<0.13,>=0.12.4->llama-index-llms-ollama) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->llama-index-core<0.13,>=0.12.4->llama-index-llms-ollama) (2.5.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.49->sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.13,>=0.12.4->llama-index-llms-ollama) (3.2.3)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.8.0->llama-index-core<0.13,>=0.12.4->llama-index-llms-ollama)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->llama-index-core<0.13,>=0.12.4->llama-index-llms-ollama)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.11/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.13,>=0.12.4->llama-index-llms-ollama) (25.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx->llama-index-core<0.13,>=0.12.4->llama-index-llms-ollama) (1.3.1)\n",
            "Collecting colorama>=0.4 (from griffe->banks<3,>=2.2.0->llama-index-core<0.13,>=0.12.4->llama-index-llms-ollama)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->banks<3,>=2.2.0->llama-index-core<0.13,>=0.12.4->llama-index-llms-ollama) (3.0.2)\n",
            "Downloading llama_index_llms_ollama-0.6.2-py3-none-any.whl (8.1 kB)\n",
            "Downloading llama_index_core-0.12.52.post1-py3-none-any.whl (7.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m65.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ollama-0.5.1-py3-none-any.whl (13 kB)\n",
            "Downloading banks-2.2.0-py3-none-any.whl (29 kB)\n",
            "Downloading Deprecated-1.2.18-py2.py3-none-any.whl (10.0 kB)\n",
            "Downloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
            "Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading llama_index_workflows-1.2.0-py3-none-any.whl (37 kB)\n",
            "Downloading setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m41.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading aiosqlite-0.21.0-py3-none-any.whl (15 kB)\n",
            "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading llama_index_instrumentation-0.3.0-py3-none-any.whl (15 kB)\n",
            "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Downloading griffe-1.8.0-py3-none-any.whl (132 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.5/132.5 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Installing collected packages: filetype, dirtyjson, setuptools, mypy-extensions, marshmallow, deprecated, colorama, aiosqlite, typing-inspect, griffe, ollama, llama-index-instrumentation, dataclasses-json, banks, llama-index-workflows, llama-index-core, llama-index-llms-ollama\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 75.2.0\n",
            "    Uninstalling setuptools-75.2.0:\n",
            "      Successfully uninstalled setuptools-75.2.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed aiosqlite-0.21.0 banks-2.2.0 colorama-0.4.6 dataclasses-json-0.6.7 deprecated-1.2.18 dirtyjson-1.0.8 filetype-1.2.0 griffe-1.8.0 llama-index-core-0.12.52.post1 llama-index-instrumentation-0.3.0 llama-index-llms-ollama-0.6.2 llama-index-workflows-1.2.0 marshmallow-3.26.1 mypy-extensions-1.1.0 ollama-0.5.1 setuptools-80.9.0 typing-inspect-0.9.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "_distutils_hack"
                ]
              },
              "id": "9c15a7158b7445148b3410200fd2ed97"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "%pip install llama-index-llms-ollama"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad297f19-998f-4485-aa2f-d67020058b7d",
      "metadata": {
        "id": "ad297f19-998f-4485-aa2f-d67020058b7d"
      },
      "outputs": [],
      "source": [
        "from llama_index.llms.ollama import Ollama"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "152ced37-9a42-47be-9a39-4218521f5e72",
      "metadata": {
        "id": "152ced37-9a42-47be-9a39-4218521f5e72"
      },
      "outputs": [],
      "source": [
        "llm = Ollama(\n",
        "    model=\"llama3.1:latest\",\n",
        "    request_timeout=120.0,\n",
        "    # Manually set the context window to limit memory usage\n",
        "    context_window=8000,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d61b10bb-e911-47fb-8e84-19828cf224be",
      "metadata": {
        "id": "d61b10bb-e911-47fb-8e84-19828cf224be"
      },
      "outputs": [],
      "source": [
        "resp = llm.complete(\"Who is Paul Graham?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3bd14f4e-c245-4384-a471-97e4ddfcb40e",
      "metadata": {
        "id": "3bd14f4e-c245-4384-a471-97e4ddfcb40e",
        "outputId": "d300a0c3-8251-4285-d6b2-9d53abb72c4a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Paul Graham is a British-American entrepreneur, programmer, and writer. He's a prominent figure in the technology industry, known for his insights on entrepreneurship, programming, and culture.\n",
            "\n",
            "Here are some key facts about Paul Graham:\n",
            "\n",
            "1. **Founder of Y Combinator**: In 2005, Graham co-founded Y Combinator (YC), a startup accelerator program that provides seed funding to early-stage companies. YC has since become one of the most successful and influential startup accelerators in the world.\n",
            "2. **Successful entrepreneur**: Before starting YC, Graham had already founded several successful startups, including Viaweb (acquired by Yahoo! in 2000), which developed an online store for eBay sellers, and PCGenie (sold to Apple).\n",
            "3. **Writer and essayist**: Graham has written numerous essays on topics such as entrepreneurship, programming, and technology culture, which have been published on his website, paulgraham.com. His writing often explores the intersection of business, technology, and human behavior.\n",
            "4. **Thought leader in startup community**: Through Y Combinator and his writings, Graham has become a respected thought leader among entrepreneurs, investors, and programmers. He's known for his straightforward advice on starting a successful company and his critiques of various aspects of the tech industry.\n",
            "5. **Education and background**: Paul Graham earned his bachelor's degree in philosophy from the University of Cambridge and later attended Harvard University, where he studied computer science.\n",
            "\n",
            "Graham is widely regarded as one of the most influential figures in the startup world, with many entrepreneurs and investors looking to him for guidance on how to build successful companies.\n"
          ]
        }
      ],
      "source": [
        "print(resp)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3ba9503c-b440-43c6-a50c-676c79993813",
      "metadata": {
        "id": "3ba9503c-b440-43c6-a50c-676c79993813"
      },
      "source": [
        "#### Call `chat` with a list of messages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee8a4a55-5680-4dc6-a44c-fc8ad7892f80",
      "metadata": {
        "id": "ee8a4a55-5680-4dc6-a44c-fc8ad7892f80"
      },
      "outputs": [],
      "source": [
        "from llama_index.core.llms import ChatMessage\n",
        "\n",
        "messages = [\n",
        "    ChatMessage(\n",
        "        role=\"system\", content=\"You are a pirate with a colorful personality\"\n",
        "    ),\n",
        "    ChatMessage(role=\"user\", content=\"What is your name\"),\n",
        "]\n",
        "resp = llm.chat(messages)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a9bfe53-d15b-4e75-9d91-8c5d024f4eda",
      "metadata": {
        "id": "2a9bfe53-d15b-4e75-9d91-8c5d024f4eda",
        "outputId": "fd80b9f2-7f83-4ce3-fefe-6aa18cd537af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "assistant: Ye be wantin' to know me name, eh? Well, matey, I be Captain Calico Jack \"Blackbeak\" McCoy, the most infamous buccaneer to ever sail the Seven Seas! *adjusts eye patch*\n",
            "\n",
            "Me ship, the \"Maverick's Revenge\", be a sturdy galleon with three masts and a hull black as coal. She be me home, me best mate, and me ticket to riches and adventure on the high seas!\n",
            "\n",
            "And don't ye be forgettin' me trusty parrot sidekick, Polly! She be squawkin' out sea shanties and insults to any landlubber who gets too close to our ship. *winks*\n",
            "\n",
            "So, what brings ye to these waters? Be ye lookin' for a bit o' treasure, or just wantin' to hear tales of me swashbucklin' exploits?\n"
          ]
        }
      ],
      "source": [
        "print(resp)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "25ad1b00-28fc-4bcd-96c4-d5b35605721a",
      "metadata": {
        "id": "25ad1b00-28fc-4bcd-96c4-d5b35605721a"
      },
      "source": [
        "### Streaming"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "13c641fa-345a-4dce-87c5-ab1f6dcf4757",
      "metadata": {
        "id": "13c641fa-345a-4dce-87c5-ab1f6dcf4757"
      },
      "source": [
        "Using `stream_complete` endpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06da1ef1-2f6b-497c-847b-62dd2df11491",
      "metadata": {
        "id": "06da1ef1-2f6b-497c-847b-62dd2df11491"
      },
      "outputs": [],
      "source": [
        "response = llm.stream_complete(\"Who is Paul Graham?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b851def-5160-46e5-a30c-5a3ef2356b79",
      "metadata": {
        "id": "1b851def-5160-46e5-a30c-5a3ef2356b79",
        "outputId": "8028cb84-b521-40ad-9302-a2da443d4c19"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Paul Graham is a British-American programmer, writer, and entrepreneur. He's best known for co-founding the online startup accelerator Y Combinator (YC) in 2005, which has become one of the most successful and influential startup accelerators in the world.\n",
            "\n",
            "Graham was born in 1964 in Cambridge, England. He studied philosophy at Durham University and later moved to the United States to work as a programmer. In the early 1990s, he co-founded several startups, including Viaweb (later renamed to PayPal), which was acquired by eBay in 2002 for $1.5 billion.\n",
            "\n",
            "In 2005, Graham co-founded Y Combinator with his fellow entrepreneurs Ron Conway and Robert Targ. The accelerator's goal is to help early-stage startups succeed by providing them with funding, mentorship, and networking opportunities. Over the years, YC has invested in over 2,000 companies, including notable successes like Dropbox, Airbnb, Reddit, and Stripe.\n",
            "\n",
            "Graham is also a prolific writer and blogger on topics related to technology, entrepreneurship, and business. His essays have been widely read and shared online, and he's known for his insightful commentary on the tech industry. Some of his most popular essays include \"The 4 Types of Startup Advice\" and \"What You'll Wish You Had Done.\"\n",
            "\n",
            "In addition to his work with Y Combinator, Graham has also written several books on programming, business, and philosophy. He's a sought-after speaker at conferences and events, and has been recognized for his contributions to the tech industry.\n",
            "\n",
            "Overall, Paul Graham is a respected figure in the startup world, known for his entrepreneurial spirit, insightful writing, and commitment to helping early-stage companies succeed."
          ]
        }
      ],
      "source": [
        "for r in response:\n",
        "    print(r.delta, end=\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ca52051d-6b28-49d7-98f5-82e266a1c7a6",
      "metadata": {
        "id": "ca52051d-6b28-49d7-98f5-82e266a1c7a6"
      },
      "source": [
        "Using `stream_chat` endpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe553190-52a9-436d-84ae-4dd99a1808f4",
      "metadata": {
        "id": "fe553190-52a9-436d-84ae-4dd99a1808f4"
      },
      "outputs": [],
      "source": [
        "from llama_index.core.llms import ChatMessage\n",
        "\n",
        "messages = [\n",
        "    ChatMessage(\n",
        "        role=\"system\", content=\"You are a pirate with a colorful personality\"\n",
        "    ),\n",
        "    ChatMessage(role=\"user\", content=\"What is your name\"),\n",
        "]\n",
        "resp = llm.stream_chat(messages)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "154c503c-f893-4b6b-8a65-a9a27b636046",
      "metadata": {
        "id": "154c503c-f893-4b6b-8a65-a9a27b636046",
        "outputId": "d08202f9-05a1-43d0-cb50-ea48e80487d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Me hearty! Me name be Captain Cutlass \"Blackheart\" McCoy, the most feared and revered pirate to ever sail the Seven Seas! *adjusts bandana*\n",
            "\n",
            "Me ship, the \"Maverick's Revenge\", be me home sweet home, and me crew, the \"Misfits of Mayhem\", be me trusty mates in plunderin' and pillagin'! We sail the seas in search of treasure, adventure, and a good swig o' grog!\n",
            "\n",
            "So, what brings ye to these waters? Are ye lookin' fer a swashbucklin' good time, or maybe just wantin' to know how to find yer lost parrot, Polly?"
          ]
        }
      ],
      "source": [
        "for r in resp:\n",
        "    print(r.delta, end=\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d4f66168",
      "metadata": {
        "id": "d4f66168"
      },
      "source": [
        "## JSON Mode\n",
        "\n",
        "Ollama also supports a JSON mode, which tries to ensure all responses are valid JSON.\n",
        "\n",
        "This is particularly useful when trying to run tools that need to parse structured outputs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d8339d4",
      "metadata": {
        "id": "4d8339d4"
      },
      "outputs": [],
      "source": [
        "llm = Ollama(\n",
        "    model=\"llama3.1:latest\",\n",
        "    request_timeout=120.0,\n",
        "    json_mode=True,\n",
        "    # Manually set the context window to limit memory usage\n",
        "    context_window=8000,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ba873c8a",
      "metadata": {
        "id": "ba873c8a",
        "outputId": "9e95a717-4147-4d52-b3ec-88902a22a6af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{ \"name\": \"Paul Graham\", \n",
            "  \" occupation\": [\"Computer Programmer\", \"Entrepreneur\", \"Venture Capitalist\"], \n",
            "  \"bestKnownFor\": [\"Co-founder of Y Combinator (YC)\", \"Creator of Hacker News\"], \n",
            "  \"books\": [\"Hackers & Painters: Big Ideas from the Computer Age\", \"The Lean Startup\"], \n",
            "  \"education\": [\"University College London (UCL)\", \"Harvard University\"], \n",
            "  \"awards\": [\"PC Magazine's Programmer of the Year award\"], \n",
            "  \"netWorth\": [\"estimated to be around $500 million\"], \n",
            "  \"personalWebsite\": [\"https://paulgraham.com/\"] }\n"
          ]
        }
      ],
      "source": [
        "response = llm.complete(\n",
        "    \"Who is Paul Graham? Output as a structured JSON object.\"\n",
        ")\n",
        "print(str(response))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1377e244",
      "metadata": {
        "id": "1377e244"
      },
      "source": [
        "## Structured Outputs\n",
        "\n",
        "We can also attach a pyndatic class to the LLM to ensure structured outputs. This will use Ollama's builtin structured output capabilities for a given pydantic class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a5b94ef",
      "metadata": {
        "id": "9a5b94ef"
      },
      "outputs": [],
      "source": [
        "from llama_index.core.bridge.pydantic import BaseModel\n",
        "\n",
        "\n",
        "class Song(BaseModel):\n",
        "    \"\"\"A song with name and artist.\"\"\"\n",
        "\n",
        "    name: str\n",
        "    artist: str"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c837c03",
      "metadata": {
        "id": "2c837c03"
      },
      "outputs": [],
      "source": [
        "llm = Ollama(\n",
        "    model=\"llama3.1:latest\",\n",
        "    request_timeout=120.0,\n",
        "    # Manually set the context window to limit memory usage\n",
        "    context_window=8000,\n",
        ")\n",
        "\n",
        "sllm = llm.as_structured_llm(Song)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "247e033d",
      "metadata": {
        "id": "247e033d",
        "outputId": "83055a93-865c-490f-9bfa-02b3655e0838"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\"name\":\"Hey Ya!\",\"artist\":\"OutKast\"}\n"
          ]
        }
      ],
      "source": [
        "from llama_index.core.llms import ChatMessage\n",
        "\n",
        "response = sllm.chat([ChatMessage(role=\"user\", content=\"Name a random song!\")])\n",
        "print(response.message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5dca7636",
      "metadata": {
        "id": "5dca7636"
      },
      "source": [
        "Or with async"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9fb526f3",
      "metadata": {
        "id": "9fb526f3",
        "outputId": "8c43d028-4bb0-4807-8f3a-e63163028e13"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\"name\":\"Mr. Blue Sky\",\"artist\":\"Electric Light Orchestra (ELO)\"}\n"
          ]
        }
      ],
      "source": [
        "response = await sllm.achat(\n",
        "    [ChatMessage(role=\"user\", content=\"Name a random song!\")]\n",
        ")\n",
        "print(response.message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cdad7904",
      "metadata": {
        "id": "cdad7904"
      },
      "source": [
        "You can also stream structured outputs! Streaming a structured output is a little different than streaming a normal string. It will yield a generator of the most up to date structured object."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d5c40157",
      "metadata": {
        "id": "d5c40157",
        "outputId": "ed9345b2-1542-4ad1-aae5-55abcf024400"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\"name\":null,\"artist\":null}\n",
            "{\"name\":null,\"artist\":null}\n",
            "{\"name\":null,\"artist\":null}\n",
            "{\"name\":null,\"artist\":null}\n",
            "{\"name\":null,\"artist\":null}\n",
            "{\"name\":\"\",\"artist\":null}\n",
            "{\"name\":\"Mr\",\"artist\":null}\n",
            "{\"name\":\"Mr.\",\"artist\":null}\n",
            "{\"name\":\"Mr. Blue\",\"artist\":null}\n",
            "{\"name\":\"Mr. Blue Sky\",\"artist\":null}\n",
            "{\"name\":\"Mr. Blue Sky\",\"artist\":null}\n",
            "{\"name\":\"Mr. Blue Sky\",\"artist\":null}\n",
            "{\"name\":\"Mr. Blue Sky\",\"artist\":null}\n",
            "{\"name\":\"Mr. Blue Sky\",\"artist\":null}\n",
            "{\"name\":\"Mr. Blue Sky\",\"artist\":null}\n",
            "{\"name\":\"Mr. Blue Sky\",\"artist\":\"\"}\n",
            "{\"name\":\"Mr. Blue Sky\",\"artist\":\"Electric\"}\n",
            "{\"name\":\"Mr. Blue Sky\",\"artist\":\"Electric Light\"}\n",
            "{\"name\":\"Mr. Blue Sky\",\"artist\":\"Electric Light Orchestra\"}\n",
            "{\"name\":\"Mr. Blue Sky\",\"artist\":\"Electric Light Orchestra\"}\n",
            "{\"name\":\"Mr. Blue Sky\",\"artist\":\"Electric Light Orchestra\"}\n"
          ]
        }
      ],
      "source": [
        "response_gen = sllm.stream_chat(\n",
        "    [ChatMessage(role=\"user\", content=\"Name a random song!\")]\n",
        ")\n",
        "for r in response_gen:\n",
        "    print(r.message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b8ae32e0",
      "metadata": {
        "id": "b8ae32e0"
      },
      "source": [
        "## Multi-Modal Support\n",
        "\n",
        "Ollama supports multi-modal models, and the Ollama LLM class natively supports images out of the box.\n",
        "\n",
        "This leverages the content blocks feature of the chat messages.\n",
        "\n",
        "Here, we leverage the `llama3.2-vision` model to answer a question about an image. If you don't have this model yet, you'll want to run `ollama pull llama3.2-vision`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "08764644",
      "metadata": {
        "id": "08764644"
      },
      "outputs": [],
      "source": [
        "!wget \"https://pbs.twimg.com/media/GVhGD1PXkAANfPV?format=jpg&name=4096x4096\" -O ollama_image.jpg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb82639e",
      "metadata": {
        "id": "bb82639e",
        "outputId": "f931ee0c-7144-4fe2-a23f-e2dd23cf3ead"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "assistant: The image depicts a cartoon alpaca wearing VR goggles and a headset, with the Google logo displayed prominently in front of it. The alpaca is characterized by its distinctive long neck, soft wool, and a pair of VR goggles perched atop its head. It is also equipped with a headset that is connected to the goggles. The alpaca's body is depicted as a cloud, which is a common visual representation of the Google brand. The overall design of the image is playful and humorous, with the alpaca's VR goggles and headset giving it a futuristic and tech-savvy appearance.\n"
          ]
        }
      ],
      "source": [
        "from llama_index.core.llms import ChatMessage, TextBlock, ImageBlock\n",
        "from llama_index.llms.ollama import Ollama\n",
        "\n",
        "llm = Ollama(\n",
        "    model=\"llama3.2-vision\",\n",
        "    request_timeout=120.0,\n",
        "    # Manually set the context window to limit memory usage\n",
        "    context_window=8000,\n",
        ")\n",
        "\n",
        "messages = [\n",
        "    ChatMessage(\n",
        "        role=\"user\",\n",
        "        blocks=[\n",
        "            TextBlock(text=\"What type of animal is this?\"),\n",
        "            ImageBlock(path=\"ollama_image.jpg\"),\n",
        "        ],\n",
        "    ),\n",
        "]\n",
        "\n",
        "resp = llm.chat(messages)\n",
        "print(resp)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "48e1d7fd",
      "metadata": {
        "id": "48e1d7fd"
      },
      "source": [
        "Close enough ;)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "93b4cbff",
      "metadata": {
        "id": "93b4cbff"
      },
      "source": [
        "## Thinking\n",
        "\n",
        "Models in Ollama support \"thinking\" -- the process of reasoning and reflecting on a response before returning a final answer.\n",
        "\n",
        "Below we show how to enable thinking in Ollama models in both streaming and non-streaming modes using the `thinking` parameter and the `qwen3:8b` model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1e3b1a77",
      "metadata": {
        "id": "1e3b1a77"
      },
      "outputs": [],
      "source": [
        "from llama_index.llms.ollama import Ollama\n",
        "\n",
        "llm = Ollama(\n",
        "    model=\"qwen3:8b\",\n",
        "    request_timeout=360,\n",
        "    thinking=True,\n",
        "    # Manually set the context window to limit memory usage\n",
        "    context_window=8000,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d27d440",
      "metadata": {
        "id": "7d27d440"
      },
      "outputs": [],
      "source": [
        "resp = llm.complete(\"What is 434 / 22?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c8bab146",
      "metadata": {
        "id": "c8bab146",
        "outputId": "da91fbf5-6951-4390-949e-0969fa9b622d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Okay, so I need to figure out what 434 divided by 22 is. Let me start by recalling how division works. Dividing a larger number by a smaller one can sometimes be tricky, especially when the numbers aren't multiples of each other. Let me see... Maybe I can use long division here. \n",
            "\n",
            "First, I should check if 22 goes into 434 evenly or if there's a remainder. Let me write it out step by step. \n",
            "\n",
            "Starting with the first digit of 434, which is 4. But 22 is larger than 4, so I can't divide 22 into 4. Then I take the first two digits, which is 43. Now, how many times does 22 go into 43? Let me think. 22 times 1 is 22, and 22 times 2 is 44. Oh, 44 is too big because 44 is more than 43. So 22 goes into 43 once. \n",
            "\n",
            "So I write 1 as the first digit of the quotient. Then, I multiply 1 by 22, which gives 22. Subtract that from 43, and I get 43 - 22 = 21. \n",
            "\n",
            "Now, bring down the next digit from 434, which is 4. So now, the new number is 214. Wait, no, actually, after bringing down the 4, it's 214? Let me check. Wait, the original number is 434. After taking the first two digits as 43, subtracting 22 gives 21, then bringing down the 4 makes it 214. Yes, that's right. \n",
            "\n",
            "Now, how many times does 22 go into 214? Let me calculate. 22 times 9 is 198, and 22 times 10 is 220. 220 is more than 214, so it goes in 9 times. \n",
            "\n",
            "So I write 9 next to the 1 in the quotient, making it 19. Multiply 9 by 22: 9*20 is 180, and 9*2 is 18, so total is 198. Subtract that from 214: 214 - 198 = 16. \n",
            "\n",
            "Now, there are no more digits to bring down, so we add a decimal point and a zero to continue the division. So, we have 16.0. \n",
            "\n",
            "Now, 22 goes into 160 how many times? Let me see. 22*7 is 154, and 22*8 is 176. 176 is too big, so it goes in 7 times. \n",
            "\n",
            "Multiply 7 by 22: 7*20=140, 7*2=14, total 154. Subtract that from 160: 160 - 154 = 6. \n",
            "\n",
            "Bring down another zero, making it 60. Now, 22 goes into 60 twice (22*2=44). Subtract 44 from 60: 60 - 44 = 16. \n",
            "\n",
            "Wait a minute, I've seen this remainder before. It was 16 after the first step, and now it's 16 again. This means the decimal will start repeating. \n",
            "\n",
            "So putting it all together, the quotient is 19.72... and the pattern will repeat. So the decimal expansion is 19.727272..., with \"72\" repeating. \n",
            "\n",
            "Let me verify if that's correct. If I multiply 22 by 19.727272..., does it equal 434? Let me check. \n",
            "\n",
            "First, 22 * 19 = 418. Then, 22 * 0.727272... Let me compute that. \n",
            "\n",
            "0.727272... is the same as 72/99, which simplifies to 8/11. So 22 * (8/11) = (22/11)*8 = 2*8 = 16. \n",
            "\n",
            "Therefore, 22*(19 + 8/11) = 22*19 + 22*(8/11) = 418 + 16 = 434. Perfect, that checks out. \n",
            "\n",
            "So the division of 434 by 22 is 19 with a remainder of 16, or as a decimal, approximately 19.727272..., repeating. \n",
            "\n",
            "Alternatively, if I want to write it as a fraction, 434 divided by 22 can be simplified. Let me see if 434 and 22 have a common factor. \n",
            "\n",
            "First, factor 22: 2*11. Let's check if 434 is divisible by 2. Yes, because it's even. 434 divided by 2 is 217. Then, check if 217 is divisible by 11. 11*19 is 209, and 11*20 is 220. So 217 - 209 = 8, so no. Therefore, the simplified fraction is 217/11. \n",
            "\n",
            "Wait, 434 divided by 2 is 217, and 22 divided by 2 is 11. So yes, 434/22 simplifies to 217/11. \n",
            "\n",
            "So, as a mixed number, that would be 19 and 8/11, since 217 divided by 11 is 19 with a remainder of 8. \n",
            "\n",
            "Therefore, the answer is 19 and 8/11, or approximately 19.7272..., repeating. \n",
            "\n",
            "But the question just asks for 434 divided by 22. Depending on how they want the answer, it could be presented as a fraction, a decimal, or a mixed number. Since the user hasn't specified, but in many cases, unless told otherwise, providing the decimal with the repeating notation might be appropriate. However, sometimes fractions are preferred. \n",
            "\n",
            "Alternatively, if they want the exact value, the fraction 217/11 is exact, and the decimal is repeating. \n",
            "\n",
            "Let me check my calculations again to be sure. \n",
            "\n",
            "First, 22*19 = 418. 434 - 418 = 16. So the remainder is 16. Therefore, 434/22 = 19 + 16/22. Simplify 16/22 by dividing numerator and denominator by 2: 8/11. So 19 8/11. \n",
            "\n",
            "Yes, that's correct. So the exact value is 19 8/11, which is approximately 19.727272... \n",
            "\n",
            "Alternatively, if they want a decimal, it's 19.727272..., with the \"72\" repeating. \n",
            "\n",
            "So I think the answer is either 19.7272... or 19 8/11. Depending on the required format. \n",
            "\n",
            "But since the user asked for the value of 434 divided by 22, and didn't specify, I should probably present both, but maybe the fraction is more precise. However, in many cases, decimal is acceptable if it's repeating. \n",
            "\n",
            "Alternatively, maybe they just want the decimal up to certain places, but since it's repeating, it's better to show the repeating decimal. \n",
            "\n",
            "So, putting it all together, the answer is 19.7272..., with the bar over 72. \n",
            "\n",
            "Alternatively, in boxed form, maybe they want the fraction? Let me check if 217/11 can be simplified further. 217 divided by 11 is 19.727..., and since 11 is a prime number, and 217 divided by 11 is 19 with remainder 8, so 217/11 is the simplest form. \n",
            "\n",
            "So, the answer is 217/11 or approximately 19.7272... \n",
            "\n",
            "But since the user might expect a decimal or a fraction. Let me check if there's a standard way. In math problems, unless specified, sometimes fractions are preferred for exactness. However, if they want a decimal, the repeating decimal is the exact value. \n",
            "\n",
            "But since the question is straightforward, maybe they just want the decimal. Let me confirm once again. \n",
            "\n",
            "Let me do the division again step by step to make sure. \n",
            "\n",
            "Dividing 434 by 22:\n",
            "\n",
            "22 into 43 (first two digits) is 1, 1*22=22, subtract from 43 gives 21. Bring down 4 to make 214. \n",
            "\n",
            "22 into 214 is 9 (since 22*9=198), subtract 198 from 214 gives 16. Bring down a 0 to make 160. \n",
            "\n",
            "22 into 160 is 7 (22*7=154), subtract 154 from 160 gives 6. Bring down a 0 to make 60. \n",
            "\n",
            "22 into 60 is 2 (22*2=44), subtract 44 from 60 gives 16. Bring down a 0 to make 160 again. \n",
            "\n",
            "Now we see the pattern repeats: 160, 154, remainder 6, then 60, 44, remainder 16, then 160... So the decimal repeats every two digits: 72. \n",
            "\n",
            "Therefore, the decimal is 19.727272..., so 19.\\overline{72}. \n",
            "\n",
            "So, in boxed form, if they want the decimal, it would be \\boxed{19.\\overline{72}} or as a fraction \\boxed{\\dfrac{217}{11}}. \n",
            "\n",
            "But since the question is \"What is 434 / 22?\" without specifying, maybe the fraction is better. However, sometimes decimal is expected. \n",
            "\n",
            "Alternatively, if they want a decimal rounded to a certain place, but since they didn't specify, the exact value is preferred. \n",
            "\n",
            "Since the user hasn't specified, but given the initial problem is straightforward division, maybe present both? Wait, but the user might expect one answer. \n",
            "\n",
            "Looking back, in many math problems, unless told otherwise, fractions are acceptable. However, if the answer is a repeating decimal, sometimes it's written with a bar. But in some contexts, decimal is preferred. \n",
            "\n",
            "Alternatively, check if 434 divided by 22 can be simplified as a mixed number. As we saw, it's 19 8/11. \n",
            "\n",
            "But again, without knowing the user's preference, it's hard to say. However, since the user is asking for the value, and given that 434 divided by 22 is a common fraction, maybe present both. But since the assistant is supposed to provide the answer boxed, perhaps the fraction is better. \n",
            "\n",
            "Wait, let me check if 217/11 is the simplest form. 217 divided by 11 is 19.727..., and since 217 and 11 have no common factors (since 11 is prime and 11 doesn't divide 217, as 11*19=209, 217-209=8), so yes, 217/11 is simplest. \n",
            "\n",
            "Alternatively, if they want a decimal, but since it's repeating, the bar notation is standard. \n",
            "\n",
            "In many standardized tests or math problems, both forms are acceptable, but the fraction is exact. However, the user might expect the decimal. \n",
            "\n",
            "Alternatively, maybe the user wants the answer as a decimal rounded to two decimal places? But that's speculative. \n",
            "\n",
            "Since the user hasn't specified, but given that the original numbers are integers, the fraction is exact, so I think providing the fraction is the safest. \n",
            "\n",
            "Therefore, the answer is 217/11, which is equal to 19 8/11. \n",
            "\n",
            "But to confirm once more, let me compute 22 * 19.7272... \n",
            "\n",
            "As I did before, 22*19 = 418, 22*0.7272... = 16, so total 418 + 16 = 434. Correct. \n",
            "\n",
            "Therefore, the exact value is 217/11 or 19 8/11. \n",
            "\n",
            "But the user might prefer the decimal with the repeating bar. \n",
            "\n",
            "In conclusion, since the user hasn't specified, but given that the problem is a division of two integers, it's better to present the exact fraction. However, in some cases, decimal is also acceptable. \n",
            "\n",
            "But in the absence of specific instructions, I think providing both would be thorough, but since the answer needs to be boxed, perhaps the fraction. \n",
            "\n",
            "Alternatively, maybe check if 434 divided by 22 can be simplified more. Wait, 434 divided by 2 is 217, and 22 divided by 2 is 11, so yes, 217/11 is simplest. \n",
            "\n",
            "Therefore, I think the answer is 217/11, which is approximately 19.7272... \n",
            "\n",
            "But given the way the question is phrased, maybe they just want the decimal? \n",
            "\n",
            "Alternatively, maybe the user expects a whole number with a remainder? But 434 divided by 22 is not a whole number. \n",
            "\n",
            "So, in conclusion, since the question is open-ended, but given that it's likely expecting a decimal or fraction, and given that fractions are exact, I'll present the fraction. \n",
            "\n",
            "Thus, the answer is 217/11, which can be written as \\boxed{\\dfrac{217}{11}}. \n",
            "\n",
            "Alternatively, if decimal is preferred, then \\boxed{19.\\overline{72}}. \n",
            "\n",
            "But to decide, maybe check if 434/22 can be simplified further. Since 217 and 11 have no common factors, as 11 is prime and 11 doesn't divide 217, the fraction is in simplest terms. \n",
            "\n",
            "Therefore, both forms are correct. However, since the user might be expecting a decimal, but in mathematical contexts, fractions are often preferred for exactness. \n",
            "\n",
            "But I need to check common practices. For example, in many math problems, if the division doesn't result in a whole number, the answer is often given as a fraction unless specified otherwise. \n",
            "\n",
            "Therefore, I think the answer should be presented as a fraction: 217/11. \n",
            "\n",
            "But to be thorough, I can mention both. However, since the user asked for the answer boxed, and typically boxed answers are either fractions or decimals. \n",
            "\n",
            "Given that, I'll go with the fraction. \n",
            "\n",
            "**Final Answer**\n",
            "The result of 434 divided by 22 is \\boxed{\\dfrac{217}{11}}.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(resp.additional_kwargs[\"thinking\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d3af8e4e",
      "metadata": {
        "id": "d3af8e4e",
        "outputId": "320bd045-7eba-48fb-f7eb-8d2391b40a06"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "To solve the division $ \\frac{434}{22} $, we begin by simplifying the fraction.\n",
            "\n",
            "---\n",
            "\n",
            "### **Step 1: Simplify the Fraction**\n",
            "\n",
            "Both 434 and 22 are divisible by 2:\n",
            "\n",
            "$$\n",
            "\\frac{434}{22} = \\frac{434 \\div 2}{22 \\div 2} = \\frac{217}{11}\n",
            "$$\n",
            "\n",
            "Now, $ \\frac{217}{11} $ is in its simplest form because 11 is a prime number and does not divide 217 evenly (11 × 19 = 209, and 217 − 209 = 8).\n",
            "\n",
            "---\n",
            "\n",
            "### **Step 2: Convert to a Mixed Number (Optional)**\n",
            "\n",
            "We can also express $ \\frac{217}{11} $ as a mixed number:\n",
            "\n",
            "- Divide 217 by 11: $ 217 \\div 11 = 19 $ with a remainder of 8.\n",
            "- Therefore, $ \\frac{217}{11} = 19 \\frac{8}{11} $\n",
            "\n",
            "---\n",
            "\n",
            "### **Step 3: Convert to Decimal (Optional)**\n",
            "\n",
            "If we convert $ \\frac{217}{11} $ to a decimal:\n",
            "\n",
            "$$\n",
            "\\frac{217}{11} = 19.727272\\ldots\n",
            "$$\n",
            "\n",
            "This is a repeating decimal, with the \"72\" repeating indefinitely. We can represent this as:\n",
            "\n",
            "$$\n",
            "19.\\overline{72}\n",
            "$$\n",
            "\n",
            "---\n",
            "\n",
            "### **Final Answer**\n",
            "\n",
            "Since the question is open-ended and does not specify the format, the exact and preferred form is the **fraction**:\n",
            "\n",
            "$$\n",
            "\\boxed{\\dfrac{217}{11}}\n",
            "$$\n"
          ]
        }
      ],
      "source": [
        "print(resp.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c83f7842",
      "metadata": {
        "id": "c83f7842"
      },
      "source": [
        "Thats a lot of thinking!\n",
        "\n",
        "Now, let's try a streaming example to make the wait less painful:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4ff2c2a",
      "metadata": {
        "id": "e4ff2c2a",
        "outputId": "9f495004-db99-4d37-9005-2346f6bd1bfa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "-------- Thinking: --------\n",
            "\n",
            "Okay, so I need to figure out what 434 divided by 22 is. Let me start by recalling how division works. I know that dividing a number by another means finding out how many times the divisor fits into the dividend. In this case, 22 is the divisor, and 434 is the dividend. \n",
            "\n",
            "First, maybe I should try to simplify this division. Let me see if both numbers can be divided by a common factor. Let me check if 22 and 434 have any common factors. The prime factors of 22 are 2 and 11. Let me check if 434 is divisible by 2. Yes, because 434 is an even number. Dividing 434 by 2 gives me 217. So, if I divide both numerator and denominator by 2, the problem becomes 217 divided by 11. That might be easier to handle.\n",
            "\n",
            "Now, I need to divide 217 by 11. Let me do this step by step. How many times does 11 go into 21? Well, 11 times 1 is 11, and 11 times 2 is 22, which is too much. So, 1 time. Subtract 11 from 21, which leaves 10. Bring down the next digit, which is 7, making it 107. Now, how many times does 11 go into 107? Let me calculate 11 times 9 is 99, and 11 times 10 is 110, which is too big. So, 9 times. Subtract 99 from 107, which leaves 8. \n",
            "\n",
            "So, putting that together, 217 divided by 11 is 19 with a remainder of 8. Therefore, 217/11 equals 19 and 8/11. But wait, since I simplified the original problem by dividing numerator and denominator by 2, I need to remember that the original division was 434 divided by 22, which is the same as (217/11). Therefore, the result is 19 and 8/11. \n",
            "\n",
            "But maybe I should check this division another way to make sure I didn't make a mistake. Let me try long division on 434 divided by 22 directly. \n",
            "\n",
            "Starting with 434 ÷ 22. First, determine how many times 22 goes into 43. 22 times 1 is 22, 22 times 2 is 44, which is too big. So, 1 time. Multiply 22 by 1, subtract from 43, get 21. Bring down the 4, making it 214. Now, how many times does 22 go into 214? Let me calculate 22 times 9 is 198, 22 times 10 is 220, which is too big. So, 9 times. Multiply 22 by 9, which is 198. Subtract from 214, which gives 16. \n",
            "\n",
            "So, the division gives me 19 with a remainder of 16. Wait, but earlier when I simplified by dividing numerator and denominator by 2, I got 19 and 8/11. But here, dividing directly gives me 19 with a remainder of 16. There's a discrepancy here. Which one is correct?\n",
            "\n",
            "Let me check. If I take 22 times 19, that's 22*20=440 minus 22, which is 418. Then, 434 - 418 is 16. So, 434 divided by 22 is 19 with a remainder of 16. But when I simplified earlier, I thought it was 19 and 8/11. That must mean I made a mistake in my simplification step. Let me go back.\n",
            "\n",
            "Original problem: 434 divided by 22. Divided numerator and denominator by 2, getting 217 divided by 11. Let me check 217 divided by 11. 11*19 is 209. 217 - 209 is 8. Therefore, 217/11 is 19 and 8/11. But according to the direct division, 434/22 is 19 with remainder 16. Wait, but if I take 217 divided by 11, which is 19.818..., and 434 divided by 22 is the same as 217 divided by 11, so they should be equal. But according to the direct division, 434 divided by 22 is 19 with remainder 16, which is 19 + 16/22, which simplifies to 19 + 8/11. Oh! Wait, 16/22 reduces to 8/11. So both methods give the same result. So, 19 and 8/11 is the same as 19.727..., which is approximately 19.727. \n",
            "\n",
            "So, in decimal form, 434 divided by 22. Let me compute that. Since 22*19 = 418, and 434 - 418 = 16. So, 16/22 is 0.727..., so the decimal is approximately 19.727. \n",
            "\n",
            "Alternatively, if I want to write this as a decimal, I can perform the division 16 divided by 22. Let me do that. 16 divided by 22. Since 16 is less than 22, we write it as 0.727... by adding decimals. 16.0 divided by 22. 22 goes into 160 seven times (22*7=154), subtract 154 from 160, get 6. Bring down a zero to make 60. 22 goes into 60 two times (22*2=44), subtract 44 from 60, get 16. Bring down a zero to make 160 again. This repeats, so it's 0.7272..., which is 0.727 recurring. Therefore, 434 divided by 22 is 19.727..., or 19 and 8/11. \n",
            "\n",
            "So, to confirm, both methods give the same result. Therefore, the answer is 19 and 8/11, or approximately 19.727. \n",
            "\n",
            "Alternatively, if I want to write it as a decimal rounded to a certain place, but since the question doesn't specify, the exact fraction is 19 8/11, or as an improper fraction, 217/11. But let me check if 217 and 11 have any common factors. 11 is a prime number. 11*19 is 209, 11*20 is 220. 217-209=8, so 217 is 11*19 +8, so it's not divisible by 11. Therefore, 217/11 is the simplest form. \n",
            "\n",
            "So, in conclusion, 434 divided by 22 is 19 and 8/11, or approximately 19.727. \n",
            "\n",
            "Wait, but maybe I should verify with another method. Let me use multiplication to check. If I take 19.727... times 22, does it equal 434? Let me compute 19.727 * 22. \n",
            "\n",
            "First, 19 * 22 = 418. Then, 0.727 * 22. Let me compute 0.727 * 22. 0.7 *22 = 15.4, and 0.027*22=0.594. Adding them together, 15.4 + 0.594 = 15.994. So total is 418 + 15.994 = 433.994, which is approximately 434, considering rounding errors. Therefore, that checks out. \n",
            "\n",
            "Alternatively, if I use fractions: 19 8/11 * 22. Let's compute that. 19*22 + (8/11)*22. 19*22 is 418, and (8/11)*22 is 8*2 = 16. So total is 418 +16=434. Perfect, that matches. Therefore, the exact value is 19 8/11. \n",
            "\n",
            "Therefore, the answer is 19 and 8/11, or as a decimal approximately 19.727. Since the question didn't specify the format, but in math problems, fractions are often preferred unless stated otherwise. So, the exact answer is 19 8/11, which can also be written as an improper fraction 217/11. \n",
            "\n",
            "Alternatively, if they want a decimal, it's approximately 19.727... So, depending on the required form. But since the original numbers are integers, the fractional form is likely the expected answer. \n",
            "\n",
            "Therefore, after all these checks, I can confidently say that 434 divided by 22 is 19 and 8/11.\n",
            "\n",
            "\n",
            "-------- Response: --------\n",
            "\n",
            "To solve $ \\frac{434}{22} $, let's proceed step by step using simplification and verification to ensure accuracy.\n",
            "\n",
            "---\n",
            "\n",
            "### Step 1: Simplify the Fraction\n",
            "\n",
            "We start by simplifying the fraction by dividing both the numerator and the denominator by their greatest common divisor (GCD). Since 22 is even and 434 is also even, both are divisible by 2.\n",
            "\n",
            "$$\n",
            "\\frac{434}{22} = \\frac{434 \\div 2}{22 \\div 2} = \\frac{217}{11}\n",
            "$$\n",
            "\n",
            "Now, we simplify $ \\frac{217}{11} $.\n",
            "\n",
            "---\n",
            "\n",
            "### Step 2: Perform the Division\n",
            "\n",
            "We divide 217 by 11:\n",
            "\n",
            "- $ 11 \\times 19 = 209 $\n",
            "- $ 217 - 209 = 8 $\n",
            "\n",
            "So, the result is:\n",
            "\n",
            "$$\n",
            "\\frac{217}{11} = 19 \\text{ remainder } 8 = 19 \\frac{8}{11}\n",
            "$$\n",
            "\n",
            "This is the **exact fractional form** of the division.\n",
            "\n",
            "---\n",
            "\n",
            "### Step 3: Convert to Decimal (Optional)\n",
            "\n",
            "To convert $ 19 \\frac{8}{11} $ to a decimal, we evaluate $ \\frac{8}{11} $:\n",
            "\n",
            "- $ \\frac{8}{11} \\approx 0.7272\\ldots $\n",
            "\n",
            "So,\n",
            "\n",
            "$$\n",
            "\\frac{434}{22} \\approx 19.7272\\ldots\n",
            "$$\n",
            "\n",
            "This is a **repeating decimal**, denoted as $ 19.\\overline{72} $.\n",
            "\n",
            "---\n",
            "\n",
            "### Final Answer\n",
            "\n",
            "$$\n",
            "\\boxed{19 \\frac{8}{11}} \\quad \\text{or} \\quad \\boxed{\\frac{217}{11}} \\quad \\text{or} \\quad \\boxed{19.7272\\ldots}\n",
            "$$\n",
            "\n",
            "The **most precise and preferred** answer is:\n",
            "\n",
            "$$\n",
            "\\boxed{19 \\frac{8}{11}}\n",
            "$$"
          ]
        }
      ],
      "source": [
        "resp_gen = llm.stream_complete(\"What is 434 / 22?\")\n",
        "\n",
        "thinking_started = False\n",
        "response_started = False\n",
        "\n",
        "for resp in resp_gen:\n",
        "    if resp.additional_kwargs.get(\"thinking_delta\", None):\n",
        "        if not thinking_started:\n",
        "            print(\"\\n\\n-------- Thinking: --------\\n\")\n",
        "            thinking_started = True\n",
        "            response_started = False\n",
        "        print(resp.additional_kwargs[\"thinking_delta\"], end=\"\", flush=True)\n",
        "    if resp.delta:\n",
        "        if not response_started:\n",
        "            print(\"\\n\\n-------- Response: --------\\n\")\n",
        "            response_started = True\n",
        "            thinking_started = False\n",
        "        print(resp.delta, end=\"\", flush=True)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}